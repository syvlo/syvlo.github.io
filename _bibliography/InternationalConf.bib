---
---

@inproceedings{Faure2022Embedding,
  title={Embedding Spatial Relations in Visual Question Answering for Remote Sensing},
  author={Faure, Maxime and Lobry, Sylvain and Kurtz, Camille and Wendling, Laurent},
  booktitle={26TH International Conference on Pattern Recognition},
  year={2022},
  abstract={Remote sensing images carry a wealth of information that is not easily accessible to end-users as it requires strong technical skills and knowledge. 
Visual Question Answering (VQA), a task that aims at answering an open-ended question in natural language from an image, can provide an easier access to this information. Considering the geographical information contained in remote sensing images, questions often embed an important spatial aspect, for instance regarding the relative position of two objects. Our objective is to better model the spatial relations in the construction of a ground-truth database of image/question/answer triplets and to assess the capacity a VQA model has to answer these questions. In this article, we propose to use histograms of forces to model the directional spatial relations between geo-localized objects. This allows a finer modeling of ambiguous relationships between objects and to provide different levels of assessment of a relation (e.g. object A is slightly/strictly to the west of object B).  Using this new dataset, we evaluate the performances of a classical VQA model and propose a curriculum learning strategy to better take into account the varying difficulty of questions embedding spatial relations.  With this approach, we show an improvement in the performances of our model, highlighting the interest of embedding spatial relations in VQA for remote sensing applications.},
  bibtex_show={true}
}

@inproceedings{chappuis2022Language,
  title={Language transformers for remote sensing visual question answering},
  author={Chappuis, Christel and Mendez, Vincent and Walt, Eliot and Lobry, Sylvain and Le Saux, Bertrand and Tuia, Devis},
  booktitle={IEEE International Geoscience and Remote Sensing Symposium IGARSS},
  year={2022},
  abstract={Remote sensing visual question answering (RSVQA) opens new avenues to promote the use of satellites data, by interfacing satellite image analysis with natural language processing. Capitalizing on the remarkable advances in natural language processing and computer vision, RSVQA aims at finding an answer to a question formulated by a human user about a remote sensing image. This is achieved by extracting representations from images and questions, and then fusing them in a joint representation. Focusing on the language part of the architecture, this study compares and evaluates the adequacy to the RSVQA task of two language models, a traditional recurrent neural network (Skip-thoughts) and a recent attention-based Transformer (BERT). We study whether large transformer models are beneficial to the task and whether fine-tuning is needed for these models to perform at their best. Our findings show that the models benefit from fine-tuning language models and that RSVQA with BERT is slightly but consistently better when properly fine-tuned.},
  bibtex_show={true}
}

@inproceedings{Thay2022LPS,
  title={Matching environmental data produced from remote sensing images to demographic data in Sub-Saharan Africa},
  author={Thay*, Lys and Rousse*, Basile and Lobry, Sylvain and Duthé, Géraldine and Wendling, Laurent and Golaz, Valérie},
  booktitle={ESA Living Planet Symposium},
  year={2022},
  bibtex_show={true}
}


@inproceedings{chappuis2021find,
  title={How to find a good image-text embedding for remote sensing visual question answering?},
  author={Chappuis, Christel and Lobry, Sylvain and Kellenberger, Benjamin and Le Saux, Bertrand and Tuia, Devis},
  booktitle={MACLEAN Workshop at ECML/PKDD 2021},
  year={2021},
  abstract={Visual question answering (VQA) has recently been intro- duced to remote sensing to make information extraction from overhead imagery more accessible to everyone. VQA considers a question (in nat- ural language, therefore easy to formulate) about an image and aims at providing an answer through a model based on computer vision and natu- ral language processing methods. As such, a VQA model needs to jointly consider visual and textual features, which is frequently done through a fusion step. In this work, we study three different fusion methodologies in the context of VQA for remote sensing and analyse the gains in ac- curacy with respect to the model complexity. Our findings indicate that more complex fusion mechanisms yield an improved performance, yet that seeking a trade-off between model complexity and performance is worthwhile in practice.},
  arxiv={2109.11848},
  bibtex_show={true}
}

@inproceedings{lobry2021rsvqa,
  title={RSVQA Meets Bigearthnet: A New, Large-Scale, Visual Question Answering Dataset for Remote Sensing},
  author={Lobry, Sylvain and Demir, Beg{\"u}m and Tuia, Devis},
  booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS},
  pages={1218--1221},
  year={2021},
  organization={IEEE},
  abstract={Visual Question Answering is a new task that can facilitate the extraction of information from images through textual queries: it aims at answering an open-ended question for- mulated in natural language about a given image. In this work, we introduce a new dataset to tackle the task of visual question answering on remote sensing images: this large- scale, open access dataset extracts image/question/answer triplets from the BigEarthNet dataset. This new dataset contains close to 15 millions samples and is openly avail- able. We present the dataset construction procedure, its characteristics and first results using a deep-learning based methodology. These first results show that the task of vi- sual question answering is challenging and opens new in- teresting research avenues at the interface of remote sensing and natural language processing. The dataset and the code to create and process it are open and freely available on https://rsvqa.sylvainlobry.com/},
  pdf={IGARSS2021.pdf},
  bibtex_show={true},
  code={https://rsvqa.sylvainlobry.com}
}

@inproceedings{lobry2020better,
  title={Better Generic Objects Counting When Asking Questions to Images: A Multitask Approach for Remote Sensing Visual Question Answering},
  author={Lobry, Sylvain and Marcos, Diego and Kellenberger, Benjamin and Tuia, Devis},
  booktitle={ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  pages={1021--1027},
  year={2020},
  bibtex_show={true},
  absract={Visual Question Answering for Remote Sensing (RSVQA) aims at extracting information from remote sensing images through queries formulated in natural language. Since the answer to the query is also provided in natural language, the system is accessible to non-experts, and therefore dramatically increases the value of remote sensing images as a source of information, for example for journalism purposes or interactive land planning. Ideally, an RSVQA system should be able to provide an answer to questions that vary both in terms of topic (presence, localization, counting) and image content. However, aiming at such flexibility generates problems related to the variability of the possible answers. A striking example is counting, where the number of objects present in a remote sensing image can vary by multiple orders of magnitude, depending on both the scene and type of objects. This represents a challenge for traditional Visual Question Answering (VQA) methods, which either become intractable or result in an accuracy loss, as the number of possible answers has to be limited. To this end, we introduce a new model that jointly solves a classification problem (which is the most common approach in VQA) and a regression problem (to answer numerical questions more precisely). An evaluation of this method on the RSVQA dataset shows that this finer numerical output comes at the cost of a small loss of performance on non-numerical questions.},
  pdf={ISPRS2020.pdf},
  bibtex_show={true}
}

@inproceedings{hua2020learning,
  title={Learning multi-label aerial image classification under label noise: A regularization approach using word embeddings},
  author={Hua, Yuansheng and Lobry, Sylvain and Mou, Lichao and Tuia, Devis and Zhu, Xiao Xiang},
  booktitle={IGARSS 2020-2020 IEEE International Geoscience and Remote Sensing Symposium},
  pages={525--528},
  year={2020},
  organization={IEEE},
  abstract={Training deep neural networks requires well-annotated datasets. However, real world datasets are often noisy, es- pecially in a multi-label scenario, i.e. where each data point can be attributed to more than one class. To this end, we propose a regularization method to learn multi-label classifi- cation networks from noisy data. This regularization is based on the assumption that semantically close classes are more likely to appear together in a given image. Hereby, we encode label correlations with prior knowledge and regularize noisy network predictions using label correlations. To evaluate its effectiveness, we perform experiments on a mutli-label aerial image dataset contaminated with controlled levels of label noise. Results indicate that networks trained using the pro- posed method outperform those directly learned from noisy labels and that the benefits increase proportionally to the amount of noise present.},
  pdf={IGARSS2020.pdf},
  bibtex_show={true}
}

@inproceedings{levering2020interpretable,
  title={Interpretable Scenicness from Sentinel-2 Imagery},
  author={Levering, Alex and Marcos, Diego and Lobry, Sylvain and Tuia, Devis},
  booktitle={IGARSS 2020-2020 IEEE International Geoscience and Remote Sensing Symposium},
  pages={3983--3986},
  year={2020},
  organization={IEEE},
  abstract={Landscape aesthetics, or scenicness, has been identified as an important ecosystem service that contribute to human health and well-being. Currently there are no methods to inventorize landscape scenicness on a large scale. In this paper we study how to upscale local assessments of scenicness provided by human observers, and we do so by using satellite images. Moreover, we develop an explicitly interpretable CNN model that allows assessing the connections between landscape scenicness and the presence of specific landcover types. To generate the landscape scenicness ground truth, we use the ScenicOrNot crowdsourcing database, which provides geo-referenced, human-based scenicness estimates for ground based photos in Great Britain. Our results show that it is feasible to predict landscape scenicness based on satellite imagery. The interpretable model performs comparably to an unconstrained model, suggesting that it is possible to learn a semantic bottleneck that represents well the present landcover classes and still contains enough information to accurately predict the location's scenicness.},
  bibtex_show={true}
}

@inproceedings{marcos2019semantically,
  title={Semantically Interpretable Activation Maps: what-where-how explanations within CNNs},
  author={Marcos, Diego and Lobry, Sylvain and Tuia, Devis},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},
  pages={4207--4215},
  year={2019},
  organization={IEEE},
  abstract={A main issue preventing the use of Convolutional Neural Networks (CNN) in end user applications is the low level of transparency in the decision process. Previous work on CNN interpretability has mostly focused either on localizing the regions of the image that contribute to the result or on building an external model that generates plausible explanations. However, the former does not provide any semantic information and the latter does not guarantee the faithfulness of the explanation. We propose an intermediate representation composed of multiple Semantically Interpretable Activation Maps (SIAM) indicating the presence of predefined attributes at different locations of the image. These attribute maps are then linearly combined to produce the final output. This gives the user insight into what the model has seen, where, and a final output directly linked to this information in a comprehensive and interpretable way. We test the method on the task of landscape scenicness (aesthetic value) estimation, using an intermediate representation of 33 attributes from the SUN Attributes database. The results confirm that SIAM makes it possible to understand what attributes in the image are contributing to the final score and where they are located. Since it is based on learning from multiple tasks and datasets, SIAM improve the explanability of the prediction without additional annotation efforts or computational overhead at inference time, while keeping good performances on both the final and intermediate tasks.},
  arxiv={1909.08442},
  bibtex_show={true}
}

@inproceedings{lobry2019visual,
  title={Visual question answering from remote sensing images},
  author={Lobry, Sylvain and Murray, Jesse and Marcos, Diego and Tuia, Devis},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={4951--4954},
  year={2019},
  abstract={Remote sensing images carry wide amounts of information beyond land cover or land use. Images contain visual and structural information that can be queried to obtain high level information about specific image content or relational dependencies between the objects sensed. This paper explores the possibility to use questions formulated in natural language as a generic and accessible way to extract this type of information from remote sensing images, i.e. visual question answering. We introduce an automatic way to create a dataset using OpenStreetMap 1 data and present some preliminary results. Our proposed approach is based on deep learning, and is trained using our new dataset.},
  organization={IEEE},
  url={https://ieeexplore.ieee.org/abstract/document/8898891},
  bibtex_show={true}
}

@inproceedings{lobry2019deep,
  title={Deep learning models to count buildings in high-resolution overhead images},
  author={Lobry, Sylvain and Tuia, Devis},
  booktitle={2019 Joint Urban Remote Sensing Event (JURSE)},
  pages={1--4},
  year={2019},
  organization={IEEE},
  url={https://ieeexplore.ieee.org/abstract/document/8809058},
  abstract={This paper addresses the problem of counting buildings in very high-resolution overhead true color imagery. We study and discuss the relevance of deep-learning based methods to this task. Two architectures and two loss functions are proposed and compared. We show that a model enforcing equivariance to rotations is beneficial for the task of counting in remotely sensed images. We also highlight the importance of robustness to outliers of the loss function when considering remote sensing applications.},
  pdf={JURSE2019.pdf},
  bibtex_show={true}
}

@inproceedings{marcos2018scale,
  title={Scale equivariance in CNNs with vector fields},
  author={Marcos, Diego and Kellenberger, Benjamin and Lobry, Sylvain and Tuia, Devis},
  booktitle={International Conference on Machine Learning (ICML)/FAIM workshop on Towards learning with limited labels: Equivariance, Invariance, and Beyond},
  year={2018},
  abstract={We study the effect of injecting local scale equivariance into Convolutional Neural Networks. This is done by applying each convolutional filter at multiple scales. The output is a vector field encoding for the maximally activating scale and the scale itself, which is further processed by the following convolutional layers. This allows all the intermediate representations to be locally scale equivariant. We show that this improves the performance of the model by over 20% in the scale equivariant task of regressing the scaling factor applied to randomly scaled MNIST digits. Furthermore, we find it also useful for scale invariant tasks, such as the actual classification of randomly scaled digits. This highlights the usefulness of allowing for a compact representation that can also learn relationships between different local scales by keeping internal scale equivariance.},
  arxiv={1807.11783},
  bibtex_show={true}
}

@inproceedings{vargas2018correcting,
  title={Correcting misaligned rural building annotations in open street map using convolutional neural networks evidence},
  author={Vargas-Munoz, John E and Marcos, Diego and Lobry, Sylvain and dos Santos, Jefersson A and Falcao, Alexandre X and Tuia, Devis},
  booktitle={IGARSS 2018-2018 IEEE International Geoscience and Remote Sensing Symposium},
  pages={1284--1287},
  year={2018},
  organization={IEEE},
  abstract={Mapping rural buildings in developing countries is crucial to monitor and plan in those vulnerable areas. Despite the existence of some rural building annotations in OpenStreetMap (OSM), those are of insufficient quantity and quality to train models able to map large areas accurately. In particular, these annotations are very often misaligned with respect to the buildings that are present in updated aerial imagery. We propose a Markov Random Field (MRF) method to correct misaligned rural building annotations. To do so, our method uses i) the correlation between candidate aligned OSM annotations and buildings roughly detected on aerial images and ii) the local consistency of the alignment vectors.},
  url={https://ieeexplore.ieee.org/abstract/document/8518711},
  bibtex_show={true}
}

@inproceedings{srivastava2018land,
  title={Land-use characterisation using Google Street View pictures and OpenStreetMap},
  author={Srivastava, Shivangi and Lobry, Sylvain and Tuia, Devis and Munoz, John Vargas},
  booktitle={21st AGILE Conference on Geographic Information Science (2018)},
  year={2018},
  abstract={This paper presents a study on the use of freely available, geo-referenced pictures from Google Street View to model and predict land-use at the urban-objects scale. This task is traditionally done manually and via photointerpretation, which is very time consuming. We propose to use a machine learning approach based on deep learning and to model land-use directly from both the pictures available from Google Street View and OpenStreetMap annotations. Because of the large availability of these two data sources, the proposed approach is scalable to cities around the globe and presents the possibility of frequent updates of the map. As base information, we use features extracted from single pictures around the object of interest; these features are issued from pre-trained convolutional neural networks. Then, we train various classifiers (Linear and RBF support vector machines, multi layer perceptron) and compare their performances. We report on a study over the city of Paris, France, where we observed that pictures coming from both inside and outside the urban-objects capture distinct, but complementary features.},
  pdf={AGILE2018.pdf},
  bibtex_show={true}
}

@INPROCEEDINGS{8438063,
  author={Deledalle, Charles-Alban and Denis, Loic and Tupin, Florence and Lobry, Sylvain},
  booktitle={EUSAR 2018; 12th European Conference on Synthetic Aperture Radar}, 
  title={Speckle reduction in PolSAR by multi-channel variance stabilization and Gaussian denoising: MuLoG}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  doi={},
  bibtex_show={true},
  abstract={Due to speckle phenomenon, some form of filtering must be applied to SAR data prior to performing any polarimetric analysis. Beyond the simple multilooking operation (i.e., moving average), several methods have been designed specifically for PolSAR filtering. The specifics of speckle noise and the correlations between polarimetric channels make PolSAR filtering more challenging than usual image restoration problems. Despite their striking performance, existing image denoising algorithms, mostly designed for additive white Gaussian noise, cannot be directly applied to PolSAR data. We bridge this gap with MuLoG by providing a general scheme that stabilizes the variance of the polarimetric channels and that can embed almost any Gaussian denoiser. We describe MuLoG approach and illustrate its performance on airborne PolSAR data using a very recent Gaussian denoiser based on a convolutional neural network.},
  url={https://ieeexplore.ieee.org/document/8438063}
}

@INPROCEEDINGS{8127445,
  author={Lobry, Sylvain and Denis, Loïc and Tupin, Florence and Fjortoft, Roger},
  booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, 
  title={Double MRF for water classification in SAR images by joint detection and reflectivity estimation}, 
  year={2017},
  volume={},
  number={},
  pages={2283-2286},
  doi={10.1109/IGARSS.2017.8127445},
  url={https://ieeexplore.ieee.org/document/8127445},
  abstract={Classification of SAR images is a challenging task as the radiometric properties of a class may not be constant throughout the image. The assumption made in most classification algorithms that a class can be modeled by constant parameters is then not valid. In this paper, we propose a classification algorithm based on two Markov random fields that accounts for local and global variations of the parameters inside the image and produces a regularized classification. This algorithm is applied on airborne TropiSAR and simulated SWOT HR data. Both quantitative and visual results are provided, demonstrating the effectiveness of the proposed method.},
  pdf={IGARSS2017_MRF.pdf},
  bibtex_show={true}
}

  @INPROCEEDINGS{8127807,
  author={Lobry, Sylvain and Tupin, Florence and Fjortoft, Roger},
  booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, 
  title={Unsupervised detection of thin water surfaces in SWOT images based on segment detection and connection}, 
  year={2017},
  volume={},
  number={},
  pages={3720-3723},
  doi={10.1109/IGARSS.2017.8127807},
  url={https://ieeexplore.ieee.org/document/8127807},
  abstract={The objective of the Surface Water and Ocean Topography (SWOT) mission is to regularly monitor the height of the earth's water surfaces. One of the challenges toward obtaining global measurements of these surfaces is to detect small water areas. In this article we introduce a method for the detection of thin water surfaces, such as rivers, in SWOT images. It combines a low-level step (segment detection) with a high-level regularization of these features. The method is then tested on a simulated SWOT image.},
  pdf={IGARSS2017_Rivers.pdf},
  bibtex_show={true}
}

@INPROCEEDINGS{8035245,
  author={Weiying Zhao and Lobry, Sylvain and Maitre, Henri and Nicolas, Jean-Marie and Tupin, Florence},
  booktitle={2017 9th International Workshop on the Analysis of Multitemporal Remote Sensing Images (MultiTemp)}, 
  title={Urban area change detection based on generalized likelihood ratio test}, 
  year={2017},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/Multi-Temp.2017.8035245},
  url={https://ieeexplore.ieee.org/document/8035245},
  abstract={Change detection methods often use denoised data because the original speckle noise has a strong influence on the detection results. The effect of using different data sources (different equivalent number of looks, original data, denoised data) and different threshold methods are studied based on four kinds of generalized likelihood ratio test approaches. NL-SAR [1] denoised data and the corresponding spatially varying equivalent number of looks are taken into account in the detection procedure. The bi-temporal experimental results on simulated data, realistic synthetic Sentinel-1 SAR data show the improvement of using equivalent number of looks of denoised data and corresponding adaptive thresholds for change detection in urban areas.},
  pdf={Multitemp2017.pdf},
  bibtex_show={true}
}

@INPROCEEDINGS{7729869,
  author={Lobry, Sylvain and Tupin, Florence and Denis, Loïc},
  booktitle={2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, 
  title={A decomposition model for scatterers change detection in multi-temporal series of SAR images}, 
  year={2016},
  volume={},
  number={},
  pages={3362-3365},
  doi={10.1109/IGARSS.2016.7729869},
  url={https://ieeexplore.ieee.org/abstract/document/7729869},
  abstract={This paper presents a method for strong scatterers change detection in synthetic aperture radar (SAR) images based on a decomposition for multi-temporal series. The formulated decomposition model jointly estimates the background of the series and the scatterers. The decomposition model retrieves possible changes in scatterers and the date at which they occurred. An exact optimization method of the model is presented and applied to a TerraSAR-X time series.},
  pdf={IGARSS2016.pdf},
  bibtex_show={true}
}

@INPROCEEDINGS{7559390,
  author={Lobry, Sylvain and Tupin, Florence and Fjortoft, Roger},
  booktitle={Proceedings of EUSAR 2016: 11th European Conference on Synthetic Aperture Radar}, 
  title={Non-Uniform Markov Random Fields for Classification of SAR Images}, 
  year={2016},
  volume={},
  number={},
  pages={1-4},
  doi={}, 
  url={https://ieeexplore.ieee.org/document/7559390},
  abstract={When dealing with SAR image classification, the class parameters may vary along the swath for several reasons. Traditional classification algorithms are then not well adapted, as they assume constant class parameters. In this paper, we propose a binary classification algorithm based on Markov Random Fields that take into account the parameters variations in the swath, and we present results obtained on airborne TropiSAR and simulated SWOT HR data.},
  pdf={EUSAR2016.pdf},
  bibtex_show={true}
}

@INPROCEEDINGS{7245772,
  author={Lobry, Sylvain and Denis, Loïc and Tupin, Florence},
  booktitle={2015 8th International Workshop on the Analysis of Multitemporal Remote Sensing Images (Multi-Temp)}, 
  title={Sparse + smooth decomposition models for multi-temporal SAR images}, 
  year={2015},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/Multi-Temp.2015.7245772},
  url={https://ieeexplore.ieee.org/document/7245772},
  abstract={SAR images have distinctive characteristics compared to optical images: speckle phenomenon produces strong fluctuations, and strong scatterers have radar signatures several orders of magnitude larger than others. We propose to use an image decomposition approach to account for these peculiarities. Several methods have been proposed in the field of image processing to decompose an image into components of different nature, such as a geometrical part and a textural part. They are generally stated as an energy minimization problem where specific penalty terms are applied to each component of the sought decomposition. We decompose temporal series of SAR images into three components: speckle, strong scatterers and background. Our decomposition method is based on a discrete optimization technique by graph-cut. We apply it to change detection tasks.},
  pdf={Multitemp2015.pdf},
  bibtex_show={true}
}




