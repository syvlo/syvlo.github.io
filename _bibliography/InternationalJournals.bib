---
---

@article{fatras2021wasserstein,
  title={Wasserstein Adversarial Regularization for learning with label noise},
  author={Fatras, Kilian and Damodaran, Bharath Bhushan and Lobry, Sylvain and Flamary, Remi and Tuia, Devis and Courty, Nicolas},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  abstract={Noisy labels often occur in vision datasets, especially when they are obtained from crowdsourcing or Web scraping. We propose a new regularization method, which enables learning robust classifiers in presence of noisy data. To achieve this goal, we propose a new adversarial regularization scheme based on the Wasserstein distance. Using this distance allows taking into account specific relations between classes by leveraging the geometric properties of the labels space. Our Wasserstein Adversarial Regularization (WAR) encodes a selective regularization, which promotes smoothness of the classifier between some classes, while preserving sufficient complexity of the decision boundary between others. We first discuss how and why adversarial regularization can be used in the context of noise and then show the effectiveness of our method on five datasets corrupted with noisy labels: in both benchmarks and real datasets, WAR outperforms the state-of-the-art competitors.},
  year={2021},
  publisher={IEEE},
  doi={https://doi.org/10.1109/TPAMI.2021.3094662},
  url={https://ieeexplore.ieee.org/abstract/document/9477020},
  arxiv={1904.03936},
  bibtex_show={true}
}


@article{MAGNUSSON2021146877,
title = {Shrub decline and expansion of wetland vegetation revealed by very high resolution land cover change detection in the Siberian lowland tundra},
journal = {Science of The Total Environment},
volume = {782},
pages = {146877},
year = {2021},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2021.146877},
url = {https://www.sciencedirect.com/science/article/pii/S0048969721019471},
pdf = {https://www.sciencedirect.com/science/article/pii/S0048969721019471/pdfft?md5=67175ce2400ef6ffa16b94da8c8b47ec&pid=1-s2.0-S0048969721019471-main.pdf},
author = {Rúna Í. Magnússon and Juul Limpens and David Kleijn and Ko {van Huissteden} and Trofim C. Maximov and Sylvain Lobry and Monique M.P.D. Heijmans},
keywords = {Siberian lowland tundra, Arctic greening, Permafrost, Land cover change, Potts model, Vegetation succession},
abstract = {Vegetation change, permafrost degradation and their interactions affect greenhouse gas fluxes, hydrology and surface energy balance in Arctic ecosystems. The Arctic shows an overall “greening” trend (i.e. increased plant biomass and productivity) attributed to expansion of shrub vegetation. However, Arctic shrub dynamics show strong spatial variability and locally “browning” may be observed. Mechanistic understanding of greening and browning trends is necessary to accurately assess the response of Arctic vegetation to a changing climate. In this context, the Siberian Arctic is an understudied region. Between 2010 and 2019, increased browning (as derived from the MODIS Enhanced Vegetation Index) was observed in the Eastern Siberian Indigirka Lowlands. To support interpretation of local greening and browning dynamics, we quantified changes in land cover and transition probabilities in a representative tundra site in the Indigirka Lowlands using a timeseries of three very high resolution (VHR) (0.5 m) satellite images acquired between 2010 and 2019. Using spatiotemporal Potts model regularization, we substantially reduced classification errors related to optical and phenological inconsistencies in the image material. VHR images show that recent browning was associated with declines in shrub, lichen and tussock vegetation and increases in open water, sedge and especially Sphagnum vegetation. Observed formation and expansion of small open water bodies in shrub dominated vegetation suggests abrupt thaw of ice-rich permafrost. Transitions from open water to sedge and Sphagnum, indicate aquatic succession upon disturbance. The overall shift towards open water and wetland vegetation suggests a wetting trend, likely associated with permafrost degradation. Landsat data confirmed widespread expansion of surface water throughout the Indigirka Lowlands. However, the increase in the area of small water bodies observed in VHR data was not visible in Landsat-derived surface water data, which suggests that VHR data is essential for early detection of small-scale disturbances and associated vegetation change in permafrost ecosystems.},
  bibtex_show={true}
}

@article{HUGHES2020166,
title = {A deep learning framework for matching of SAR and optical imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {169},
pages = {166-179},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302598},
pdf = {https://www.sciencedirect.com/science/article/pii/S0924271620302598/pdfft?md5=7dd273fad86fe7b554fa7c2ea1def329&pid=1-s2.0-S0924271620302598-main.pdf},
author = {Lloyd Haydn Hughes and Diego Marcos and Sylvain Lobry and Devis Tuia and Michael Schmitt},
keywords = {Multi-modal image matching, Image registration, Feature detection, Deep learning, Synthetic Aperture Radar (SAR), Optical imagery},
abstract = {SAR and optical imagery provide highly complementary information about observed scenes. A combined use of these two modalities is thus desirable in many data fusion scenarios. However, any data fusion task requires measurements to be accurately aligned. While for both data sources images are usually provided in a georeferenced manner, the geo-localization of optical images is often inaccurate due to propagation of angular measurement errors. Many methods for the matching of homologous image regions exist for both SAR and optical imagery, however, these methods are unsuitable for SAR-optical image matching due to significant geometric and radiometric differences between the two modalities. In this paper, we present a three-step framework for sparse image matching of SAR and optical imagery, whereby each step is encoded by a deep neural network. We first predict regions in each image which are deemed most suitable for matching. A correspondence heatmap is then generated through a multi-scale, feature-space cross-correlation operator. Finally, outliers are removed by classifying the correspondence surface as a positive or negative match. Our experiments show that the proposed approach provides a substantial improvement over previous methods for SAR-optical image matching and can be used to register even large-scale scenes. This opens up the possibility of using both types of data jointly, for example for the improvement of the geo-localization of optical satellite imagery or multi-sensor stereogrammetry.},
  bibtex_show={true}
}

@ARTICLE{9088993,
  author={Lobry, Sylvain and Marcos, Diego and Murray, Jesse and Tuia, Devis},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={RSVQA: Visual Question Answering for Remote Sensing Data}, 
  year={2020},
  volume={58},
  number={12},
  pages={8555-8566},
  url={https://ieeexplore.ieee.org/abstract/document/9088993},
  arxiv={2003.07333},
  abstract={This article introduces the task of visual question answering for remote sensing data (RSVQA). Remote sensing images contain a wealth of information, which can be useful for a wide range of tasks, including land cover classification, object counting, or detection. However, most of the available methodologies are task-specific, thus inhibiting generic and easy access to the information contained in remote sensing data. As a consequence, accurate remote sensing product generation still requires expert knowledge. With RSVQA, we propose a system to extract information from remote sensing data that is accessible to every user: we use questions formulated in natural language and use them to interact with the images. With the system, images can be queried to obtain high-level information specific to the image content or relational dependencies between objects visible in the images. Using an automatic method introduced in this article, we built two data sets (using low- and high-resolution data) of image/question/answer triplets. The information required to build the questions and answers is queried from OpenStreetMap (OSM). The data sets can be used to train (when using supervised methods) and evaluate models to solve the RSVQA task. We report the results obtained by applying a model based on convolutional neural networks (CNNs) for the visual part and a recurrent neural network (RNN) for the natural language part of this task. The model is trained on the two data sets, yielding promising results in both cases.},
  doi={10.1109/TGRS.2020.2988782},
  bibtex_show={true},
  code={https://rsvqa.sylvainlobry.com}
}


@ARTICLE{8897698,
  author={Lobry, Sylvain and Denis, Loïc and Williams, Brent and Fjørtoft, Roger and Tupin, Florence},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Water Detection in SWOT HR Images Based on Multiple Markov Random Fields}, 
  year={2019},
  volume={12},
  number={11},
  pages={4315-4326},
  abstract={One of the main objectives of the surface water and ocean topography (SWOT) mission, scheduled for launch in 2021, is to measure inland water levels using synthetic aperture radar (SAR) interferometry. A key step toward this objective is to precisely detect water areas. In this article, we present a method to detect water in SWOT images. Water is detected based on the relative brightness of the water and nonwater surfaces. Water brightness varies throughout the swath because of system parameters (i.e., the antenna pattern), as well as the phenomenology such as wind speed and surface roughness. To handle the effects of brightness variability, we propose to model the problem with one Markov random field (MRF) on the binary classification map, and two other MRFs to regularize the estimation of the class parameters (i.e., the land and water background power images). Our experiments show that the proposed method is more robust to the expected variations in SWOT images than traditional approaches.},
  url={https://ieeexplore.ieee.org/document/8897698},
  doi={10.1109/JSTARS.2019.2948788},
  bibtex_show={true},
  pdf={JSTARS2016.pdf},
  project={SWOT}
}

@ARTICLE{8807383,
  author={Kellenberger, Benjamin and Marcos, Diego and Lobry, Sylvain and Tuia, Devis},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Half a Percent of Labels is Enough: Efficient Animal Detection in UAV Imagery Using Deep CNNs and Active Learning}, 
  year={2019},
  volume={57},
  number={12},
  pages={9524-9533},
  abstract={We present an Active Learning (AL) strategy for reusing a deep Convolutional Neural Network (CNN)-based object detector on a new data set. This is of particular interest for wildlife conservation: given a set of images acquired with an Unmanned Aerial Vehicle (UAV) and manually labeled ground truth, our goal is to train an animal detector that can be reused for repeated acquisitions, e.g., in follow-up years. Domain shifts between data sets typically prevent such a direct model application. We thus propose to bridge this gap using AL and introduce a new criterion called Transfer Sampling (TS). TS uses Optimal Transport (OT) to find corresponding regions between the source and the target data sets in the space of CNN activations. The CNN scores in the source data set are used to rank the samples according to their likelihood of being animals, and this ranking is transferred to the target data set. Unlike conventional AL criteria that exploit model uncertainty, TS focuses on very confident samples, thus allowing quick retrieval of true positives in the target data set, where positives are typically extremely rare and difficult to find by visual inspection. We extend TS with a new window cropping strategy that further accelerates sample retrieval. Our experiments show that with both strategies combined, less than half a percent of oracle-provided labels are enough to find almost 80% of the animals in challenging sets of UAV images, beating all baselines by a margin.},
  arxiv={1907.07319},
  url={https://ieeexplore.ieee.org/document/8807383},
  doi={10.1109/TGRS.2019.2927393},
  bibtex_show={true}
}

@article{VARGASMUNOZ2019283,
title = {Correcting rural building annotations in OpenStreetMap using convolutional neural networks},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {147},
pages = {283-293},
year = {2018},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2018.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S092427161830306X},
author = {John E. Vargas-Muñoz and Sylvain Lobry and Alexandre X. Falcão and Devis Tuia},
keywords = {Very high resolution mapping, Convolutional neural networks, Shape priors, OpenStreetMap, Volunteered geographical information, Update of vector maps},
abstract = {Rural building mapping is paramount to support demographic studies and plan actions in response to crisis that affect those areas. Rural building annotations exist in OpenStreetMap (OSM), but their quality and quantity are not sufficient for training models that can create accurate rural building maps. The problems with these annotations essentially fall into three categories: (i) most commonly, many annotations are geometrically misaligned with the updated imagery; (ii) some annotations do not correspond to buildings in the images (they are misannotations or the buildings have been destroyed); and (iii) some annotations are missing for buildings in the images (the buildings were never annotated or were built between subsequent image acquisitions). First, we propose a method based on Markov Random Field (MRF) to align the buildings with their annotations. The method maximizes the correlation between annotations and a building probability map while enforcing that nearby buildings have similar alignment vectors. Second, the annotations with no evidence in the building probability map are removed. Third, we present a method to detect non-annotated buildings with predefined shapes and add their annotation. The proposed methodology shows considerable improvement in accuracy of the OSM annotations for two regions of Tanzania and Zimbabwe, being more accurate than state-of-the-art baselines.},
  bibtex_show={true}
}

@article{Shivangi_LU,
author = {Shivangi Srivastava and John E. Vargas Muñoz and Sylvain Lobry and Devis Tuia},
title = {Fine-grained landuse characterization using ground-based pictures: a deep learning solution based on globally available data},
journal = {International Journal of Geographical Information Science},
volume = {34},
number = {6},
pages = {1117-1136},
year  = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/13658816.2018.1542698},
pdf={https://www.tandfonline.com/doi/pdf/10.1080/13658816.2018.1542698?needAccess=true},
URL = {https://doi.org/10.1080/13658816.2018.1542698},
eprint = {https://doi.org/10.1080/13658816.2018.1542698},
abstract = { ABSTRACTWe study the problem of landuse characterization at the urban-object level using deep learning algorithms. Traditionally, this task is performed by surveys or manual photo interpretation, which are expensive and difficult to update regularly. We seek to characterize usages at the single object level and to differentiate classes such as educational institutes, hospitals and religious places by visual cues contained in side-view pictures from Google Street View (GSV). These pictures provide geo-referenced information not only about the material composition of the objects but also about their actual usage, which otherwise is difficult to capture using other classical sources of data such as aerial imagery. Since the GSV database is regularly updated, this allows to consequently update the landuse maps, at lower costs than those of authoritative surveys. Because every urban-object is imaged from a number of viewpoints with street-level pictures, we propose a deep-learning based architecture that accepts arbitrary number of GSV pictures to predict the fine-grained landuse classes at the object level. These classes are taken from OpenStreetMap. A quantitative evaluation of the area of Île-de-France, France shows that our model outperforms other deep learning-based methods, making it a suitable alternative to manual landuse characterization.},
  bibtex_show={true}
}

@ARTICLE{7488202,
  author={Lobry, Sylvain and Denis, Loïc and Tupin, Florence},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Multitemporal SAR Image Decomposition into Strong Scatterers, Background, and Speckle}, 
  year={2016},
  volume={9},
  number={8},
  pages={3419-3429},
  doi={10.1109/JSTARS.2016.2555579},
  url={https://ieeexplore.ieee.org/document/7488202},
  pdf={JSTARS2016.pdf},
  abstract={Speckle phenomenon in synthetic aperture radar (SAR) images makes their visual and automatic interpretation a difficult task. To reduce strong fluctuations due to speckle, total variation (TV) regularization has been proposed by several authors to smooth out noise without blurring edges. A specificity of SAR images is the presence of strong scatterers having a radiometry several orders of magnitude larger than their surrounding region. These scatterers, especially present in urban areas, limit the effectiveness of TV regularization as they break the assumption of an image made of regions of constant radiometry. To overcome this limitation, we propose in this paper an image decomposition approach. There exist numerous methods to decompose an image into several components, notably to separate textural and geometrical information. These decomposition models are generally recast as energy minimization problems involving a different penalty term for each of the components. In this framework, we propose an energy suitable for the decomposition of SAR images into speckle, a smooth background, and strong scatterers, and discuss its minimization using max-flow/min-cut algorithms. We make the connection between the minimization problem considered, involving the L0 pseudonorm, and the generalized likelihood ratio test used in detection theory. The proposed decomposition jointly performs the detection of strong scatterers and the estimation of the background radiometry. Given the increasing availability of time series of SAR images, we consider the decomposition of a whole time series. New change detection methods can be based on the temporal analysis of the components obtained from our decomposition.}
}

